{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cellUniqueIdByVincent": "2398e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import Tuple, Optional, Dict, Any\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellUniqueIdByVincent": "286dd"
   },
   "outputs": [],
   "source": [
    "def calculate_age_in_months(day, birth_datetime):\n",
    "    current_day = pd.to_datetime(day)\n",
    "    birth_date = pd.to_datetime(birth_datetime)\n",
    "\n",
    "    # Calculate the difference in years and months\n",
    "    years_diff = current_day.year - birth_date.year\n",
    "    months_diff = current_day.month - birth_date.month\n",
    "    days_diff = current_day.day - birth_date.day\n",
    "\n",
    "    # Adjust for day of month\n",
    "    if days_diff < 0:\n",
    "        months_diff -= 1\n",
    "\n",
    "    return years_diff * 12 + months_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "807c9"
   },
   "outputs": [],
   "source": [
    "def find_last_drug_usage(sepsis_group, drugs_group):\n",
    "    \"\"\"\n",
    "    Find the most recent drug administration before or at each sepsis measurement.\n",
    "\n",
    "    Args:\n",
    "        sepsis_group (pd.DataFrame): DataFrame containing sepsis measurements with 'measurement_datetime'\n",
    "        drugs_group (pd.DataFrame): DataFrame containing drug administrations with 'drug_datetime_hourly',\n",
    "                                  'drug_concept_id', and 'route_concept_id'\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Original sepsis_group with added 'last_drug_concept_id' and 'last_route_concept_id' columns\n",
    "    \"\"\"\n",
    "    # Handle empty inputs\n",
    "    if sepsis_group.empty or drugs_group.empty:\n",
    "        sepsis_group['last_drug_concept_id'] = None\n",
    "        sepsis_group['last_route_concept_id'] = None\n",
    "        return sepsis_group\n",
    "\n",
    "    # Convert to datetime if needed\n",
    "    sepsis_group = sepsis_group.copy()\n",
    "    drugs_group = drugs_group.copy()\n",
    "    sepsis_group['measurement_datetime'] = pd.to_datetime(sepsis_group['measurement_datetime'])\n",
    "    drugs_group['drug_datetime_hourly'] = pd.to_datetime(drugs_group['drug_datetime_hourly'])\n",
    "\n",
    "    # Sort data\n",
    "    sepsis_group = sepsis_group.sort_values('measurement_datetime')\n",
    "    drugs_group = drugs_group.sort_values('drug_datetime_hourly')\n",
    "\n",
    "    # Use merge_asof for efficient time-based merging\n",
    "    result = pd.merge_asof(\n",
    "        left=sepsis_group,\n",
    "        right=drugs_group[['drug_datetime_hourly', 'drug_concept_id', 'route_concept_id']],\n",
    "        left_on='measurement_datetime',\n",
    "        right_on='drug_datetime_hourly',\n",
    "        direction='backward'  # Find last drug <= measurement time\n",
    "    )\n",
    "\n",
    "    # Rename and clean up columns\n",
    "    result = result.rename(columns={\n",
    "        'drug_concept_id': 'last_drug_concept_id',\n",
    "        'route_concept_id': 'last_route_concept_id'\n",
    "    }).drop(columns=['drug_datetime_hourly'], errors='ignore')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "d6362"
   },
   "outputs": [],
   "source": [
    "def create_dataset(\n",
    "    data_type: str = \"train\",\n",
    "    encoders: Optional[Dict] = None,\n",
    "    base_path: str = \"/Users/harrisonekpobimi/Desktop/sepsis hackathon prediction/\",\n",
    "    n_jobs: int = -1\n",
    ") -> Tuple[pd.DataFrame, Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Optimized function to create dataset for sepsis prediction with correct folder structure.\n",
    "    \"\"\"\n",
    "    if encoders is None:\n",
    "        encoders = {}\n",
    "\n",
    "    # Set up paths\n",
    "    data_dir = f\"{base_path.rstrip('/')}/{data_type}ing_data/\"\n",
    "    is_train = (data_type == \"train\")\n",
    "\n",
    "    # 1) Load and preprocess sepsis data\n",
    "    sepsis_file = f\"{data_dir}SepsisLabel_{data_type}.csv\"\n",
    "    df_sepsis = pd.read_csv(sepsis_file)\n",
    "    df_sepsis = df_sepsis.drop_duplicates().sort_values([\"person_id\", \"measurement_datetime\"])\n",
    "    df_sepsis['measurement_datetime'] = pd.to_datetime(df_sepsis['measurement_datetime'], errors=\"coerce\")\n",
    "    df_sepsis['day'] = df_sepsis['measurement_datetime'].dt.date.astype(str)\n",
    "    df_sepsis['time_since_last_measurement'] = df_sepsis.groupby('person_id')['measurement_datetime'].diff().dt.total_seconds() / 3600\n",
    "    df_sepsis['time_since_last_measurement'] = df_sepsis['time_since_last_measurement'].fillna(0)\n",
    "\n",
    "    # Drop rows with missing person_id or measurement_datetime\n",
    "    before = len(df_sepsis)\n",
    "    df_sepsis = df_sepsis.dropna(subset=['person_id', 'measurement_datetime'])\n",
    "    after = len(df_sepsis)\n",
    "    if before != after:\n",
    "        print(f\"Dropped {before - after} rows from sepsis data due to missing person_id or measurement_datetime.\")\n",
    "\n",
    "    # 2) Process demographic data\n",
    "    demo_file = f\"{data_dir}person_demographics_episode_{data_type}.csv\"\n",
    "    df_demo = pd.read_csv(demo_file)\n",
    "    df_demo = df_demo.sort_values('visit_start_date').drop_duplicates('person_id', keep='last')\n",
    "\n",
    "    # Merge with sepsis data\n",
    "    df = pd.merge(df_sepsis, df_demo, on='person_id', how='left')\n",
    "    df['birth_datetime'] = pd.to_datetime(df['birth_datetime'], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing birth_datetime\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=['birth_datetime'])\n",
    "    after = len(df)\n",
    "    if before != after:\n",
    "        print(f\"Dropped {before - after} rows after merge due to missing birth_datetime.\")\n",
    "\n",
    "    def safe_month_diff(row):\n",
    "        if pd.isna(row['measurement_datetime']) or pd.isna(row['birth_datetime']):\n",
    "            return np.nan\n",
    "        return (row['measurement_datetime'].to_period('M') - row['birth_datetime'].to_period('M')).n\n",
    "\n",
    "    df['age_in_months'] = df.apply(safe_month_diff, axis=1)\n",
    "    df = df.drop(columns=['visit_occurrence_id', 'visit_start_date', 'birth_datetime'], errors='ignore')\n",
    "\n",
    "    # 3) Process drug data\n",
    "    def process_drugs(person_id, grp, df_drugs):\n",
    "        grp_drugs = df_drugs[df_drugs[\"person_id\"] == person_id]\n",
    "        return find_last_drug_usage(grp, grp_drugs)\n",
    "\n",
    "    try:\n",
    "        df_drugs = pd.read_csv(f\"{data_dir}drugsexposure_{data_type}.csv\")\n",
    "        df_drugs['drug_datetime_hourly'] = pd.to_datetime(df_drugs['drug_datetime_hourly'], errors=\"coerce\")\n",
    "\n",
    "        # Process in parallel\n",
    "        groups = [(pid, grp) for pid, grp in df.groupby('person_id')]\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(process_drugs)(pid, grp, df_drugs)\n",
    "            for pid, grp in groups\n",
    "        )\n",
    "        df = pd.concat(results, ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Drug data not found at {data_dir}drugsexposure_{data_type}.csv\")\n",
    "\n",
    "    # 4) Process observation data\n",
    "    try:\n",
    "        obs_file = f\"{data_dir}measurement_meds_{data_type}.csv\"\n",
    "        df_obs = pd.read_csv(obs_file)\n",
    "        df_obs['day'] = pd.to_datetime(df_obs['measurement_datetime'], errors=\"coerce\").dt.date.astype(str)\n",
    "\n",
    "        # Filter outliers\n",
    "        if 'Heart rate' in df_obs.columns and 'Respiratory rate' in df_obs.columns:\n",
    "            df_obs = df_obs[df_obs[\"Heart rate\"].between(0, 200) &\n",
    "                          df_obs[\"Respiratory rate\"].between(0, 40)]\n",
    "\n",
    "            # Aggregate by day\n",
    "            obs_agg = df_obs.groupby([\"person_id\", \"day\"]).agg({\n",
    "                \"Body temperature\": \"max\",\n",
    "                \"Respiratory rate\": \"max\",\n",
    "                \"Heart rate\": \"max\",\n",
    "                \"Measurement of oxygen saturation at periphery\": \"mean\"\n",
    "            }).reset_index()\n",
    "\n",
    "            df = df.merge(obs_agg, on=[\"person_id\", \"day\"], how=\"left\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Observation data not found at {data_dir}measurement_meds_{data_type}.csv\")\n",
    "\n",
    "    # 5) Process lab data\n",
    "    try:\n",
    "        lab_file = f\"{data_dir}measurement_lab_{data_type}.csv\"\n",
    "        df_lab = pd.read_csv(lab_file)\n",
    "        df_lab.columns = df_lab.columns.str.replace(r'[\\[\\]]', '', regex=True)\n",
    "        df_lab['day'] = pd.to_datetime(df_lab['measurement_datetime'], errors=\"coerce\").dt.date.astype(str)\n",
    "\n",
    "        # Get numeric columns and aggregate\n",
    "        numeric_cols = df_lab.select_dtypes(include=np.number).columns.tolist()\n",
    "        if 'person_id' in numeric_cols:\n",
    "            numeric_cols.remove('person_id')\n",
    "        if 'visit_occurrence_id' in numeric_cols:\n",
    "            numeric_cols.remove('visit_occurrence_id')\n",
    "\n",
    "        if numeric_cols:\n",
    "            lab_agg = df_lab.groupby(['person_id', 'day'])[numeric_cols].mean().reset_index()\n",
    "            df = df.merge(lab_agg, on=['person_id', 'day'], how='left')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lab data not found at {data_dir}measurement_lab_{data_type}.csv\")\n",
    "\n",
    "    # 6) Handle missing values\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    if not numeric_cols.empty:\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "    # 7) Encode categorical variables\n",
    "    cat_cols = [\"gender\", \"current_drug_concept_id\", \"current_route_concept_id\",\n",
    "                \"last_drug_concept_id\", \"last_route_concept_id\"]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "            if is_train:\n",
    "                le = LabelEncoder()\n",
    "                df[col] = le.fit_transform(df[col])\n",
    "                encoders[col] = le\n",
    "            else:\n",
    "                le = encoders.get(col)\n",
    "                if le is not None:\n",
    "                    mask = df[col].isin(le.classes_)\n",
    "                    if not mask.all():\n",
    "                        df.loc[~mask, col] = le.classes_[0]\n",
    "                    df[col] = le.transform(df[col])\n",
    "\n",
    "    # 8) Final cleanup\n",
    "    cols_to_drop = ['day', 'visit_occurrence_id', 'visit_occurence_id',\n",
    "                   'Ionised calcium measurement', 'Unnamed: 0']\n",
    "    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "    return df, encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellUniqueIdByVincent": "abb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 15 rows from sepsis data due to missing person_id or measurement_datetime.\n",
      "Train dataset shape: (331624, 48)\n",
      "Test dataset shape: (130483, 47)\n",
      "Train: missing person_id: 0, missing day: N/A\n",
      "Test: missing person_id: 0, missing day: N/A\n"
     ]
    }
   ],
   "source": [
    "encoders = {}  # Store label encoders here\n",
    "\n",
    "# Create the TRAIN dataset\n",
    "try:\n",
    "    df_train, encoders = create_dataset(\"train\", encoders=encoders)\n",
    "    print(f\"Train dataset shape: {df_train.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating train dataset: {e}\")\n",
    "    df_train = None\n",
    "\n",
    "# Create the TEST dataset\n",
    "try:\n",
    "    df_test, _ = create_dataset(\"test\", encoders=encoders)\n",
    "    print(f\"Test dataset shape: {df_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating test dataset: {e}\")\n",
    "    df_test = None\n",
    "\n",
    "# Check for missing merge keys in train and test\n",
    "def check_merge_keys(df, name):\n",
    "    if df is not None:\n",
    "        missing_person = df['person_id'].isna().sum() if 'person_id' in df.columns else 'N/A'\n",
    "        missing_day = df['day'].isna().sum() if 'day' in df.columns else 'N/A'\n",
    "        print(f\"{name}: missing person_id: {missing_person}, missing day: {missing_day}\")\n",
    "\n",
    "check_merge_keys(df_train, 'Train')\n",
    "check_merge_keys(df_test, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cellUniqueIdByVincent": "950fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>measurement_datetime</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>time_since_last_measurement</th>\n",
       "      <th>age_in_months</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_drug_concept_id</th>\n",
       "      <th>last_route_concept_id</th>\n",
       "      <th>Body temperature</th>\n",
       "      <th>Respiratory rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Bilirubin measurement</th>\n",
       "      <th>Partial thromboplastin time</th>\n",
       "      <th>activated</th>\n",
       "      <th>Total white blood count</th>\n",
       "      <th>Platelet count</th>\n",
       "      <th>White blood cell count</th>\n",
       "      <th>Blood venous pH</th>\n",
       "      <th>D-dimer level</th>\n",
       "      <th>Blood arterial pH</th>\n",
       "      <th>Hemoglobin Moles/volume in Blood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510305</td>\n",
       "      <td>2019-07-01 16:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>30.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>510305</td>\n",
       "      <td>2019-07-01 17:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>30.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>510305</td>\n",
       "      <td>2019-07-02 13:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>30.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.38</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>510305</td>\n",
       "      <td>2019-07-03 09:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510305</td>\n",
       "      <td>2019-07-03 10:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>36.8</td>\n",
       "      <td>35.929688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id measurement_datetime  SepsisLabel  time_since_last_measurement  \\\n",
       "0     510305  2019-07-01 16:00:00            0                          0.0   \n",
       "1     510305  2019-07-01 17:00:00            0                          1.0   \n",
       "2     510305  2019-07-02 13:00:00            0                         20.0   \n",
       "3     510305  2019-07-03 09:00:00            0                         20.0   \n",
       "4     510305  2019-07-03 10:00:00            0                          1.0   \n",
       "\n",
       "   age_in_months  gender  last_drug_concept_id  last_route_concept_id  \\\n",
       "0             26       0                    39                     10   \n",
       "1             26       0                    39                     10   \n",
       "2             26       0                    34                      2   \n",
       "3             26       0                    34                      2   \n",
       "4             26       0                    34                      2   \n",
       "\n",
       "   Body temperature  Respiratory rate  ...  Bilirubin measurement  \\\n",
       "0              36.8         35.929688  ...                    5.1   \n",
       "1              36.8         35.929688  ...                    5.1   \n",
       "2              36.8         35.929688  ...                    5.1   \n",
       "3              36.8         35.929688  ...                    5.1   \n",
       "4              36.8         35.929688  ...                    5.1   \n",
       "\n",
       "   Partial thromboplastin time   activated  Total white blood count  \\\n",
       "0                         30.6         4.0                     44.0   \n",
       "1                         30.6         4.0                     44.0   \n",
       "2                         30.6         9.5                    197.0   \n",
       "3                         31.9         4.3                     41.0   \n",
       "4                         31.9         4.3                     41.0   \n",
       "\n",
       "   Platelet count  White blood cell count  Blood venous pH  D-dimer level  \\\n",
       "0             0.6                    7.42             3.69           7.38   \n",
       "1             0.6                    7.42             3.69           7.38   \n",
       "2             0.1                    7.38             3.69           7.38   \n",
       "3             0.0                    7.38             3.69           7.38   \n",
       "4             0.0                    7.38             3.69           7.38   \n",
       "\n",
       "   Blood arterial pH  Hemoglobin Moles/volume in Blood  \n",
       "0                8.6                              1.25  \n",
       "1                8.6                              1.25  \n",
       "2               10.5                              1.25  \n",
       "3                8.9                              1.25  \n",
       "4                8.9                              1.25  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cellUniqueIdByVincent": "a33f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepsisLabel\n",
      "0    324750\n",
      "1      6874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df_train[\"SepsisLabel\"].value_counts()\n",
    "print(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "vincent": {
   "sessionId": "4de33abf56842edd6a7ba9f3_2025-12-29T15-54-32-307Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
